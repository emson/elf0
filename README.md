# üßù Elf0 - sElf Improving Agentic YAML Workflows

**Build powerful AI agent workflows using simple YAML files. Zero complex coding required.**

> ‚ö†Ô∏è **IMPORTANT: NOT PRODUCTION READY - USE AT YOUR OWN RISK**
>
> This software is experimental and in active development. Elf0 workflows can execute custom Python functions, interact with external tools, and perform system operations that may cause data loss, security vulnerabilities, or damage to your system. 
>
> **Before using Elf0:**
> - Review all workflow files before execution
> - Test in isolated environments first
> - Never run untrusted workflows
> - Backup important data
> - Use appropriate security measures
>
> **The author(s) provide this software "AS IS" without any warranties and assume no liability for any damages, data loss, security breaches, or other issues that may result from its use. Users are solely responsible for ensuring safe and appropriate usage.**

Elf0 lets you create multi-step AI workflows by describing what you want in YAML. Chain (graph) together different AI models, integrate with external tools, and even use AI to improve your workflows automatically.

```bash
# Simple AI workflow in one command
uv run elf0 agent specs/basic/chat_simple_v1.yaml --prompt "Explain quantum computing in simple terms"

# Reference files automatically with @filename.ext syntax  
uv run elf0 agent specs/basic/chat_simple_v1.yaml --prompt "Review this code @src/elf0/cli.py and suggest improvements"

# Let AI improve your workflows
uv run elf0 improve yaml specs/basic/chat_simple_v1.yaml --prompt "Make this workflow more efficient"
```

## ‚ö° Quick Start (5 minutes)

> ‚ö†Ô∏è **Read the [Security & Safety Considerations](#-security--safety-considerations) section before proceeding**

Get up and running with your first AI workflow in 5 minutes:

### 1. Prerequisites
- **Python 3.13+** ([Download here](https://python.org/downloads/))
- **uv package manager** by Astral ([Install guide](https://docs.astral.sh/uv/getting-started/installation/)) - A blazingly fast Python package manager that replaces pip/conda
- **An API key** from [OpenAI](https://platform.openai.com/api-keys), [Anthropic](https://console.anthropic.com/), or use [Ollama](https://ollama.ai/) locally

### 2. Install Elf0
```bash
git clone https://github.com/emson/elf.git
cd elf
uv venv
source .venv/bin/activate  # On Windows: .venv\Scripts\activate
uv pip install -e .
```

### 3. Set up your API keys
Configure your environment using the provided template:

```bash
# Copy the environment template
cp .env.example .env

# Edit .env with your actual API keys
# The file contains detailed instructions and all supported providers
```

**Quick setup for common providers:**
```bash
# For OpenAI (recommended for beginners)
export OPENAI_API_KEY="your-api-key-here"

# OR for Anthropic (Claude)
export ANTHROPIC_API_KEY="your-api-key-here"

# OR use Ollama locally (no API key needed)
# Install Ollama from https://ollama.ai/ and run: ollama pull llama2
```

**Supported LLM providers:**
- **OpenAI**: GPT-4, GPT-3.5, etc. - Get API key from [platform.openai.com](https://platform.openai.com/api-keys)
- **Anthropic**: Claude models - Get API key from [console.anthropic.com](https://console.anthropic.com/)
- **DeepSeek**: Advanced models - Get API key from [platform.deepseek.com](https://platform.deepseek.com/)
- **Ollama**: Local models (free) - No API key required, install from [ollama.ai](https://ollama.ai/)

### 4. Run your first workflow
```bash
uv run elf0 agent specs/basic/chat_simple_v1.yaml --prompt "Write a haiku about programming"
```

**üéâ It works!** You should see a beautiful haiku generated by AI. 

---

## üì¶ Complete Installation Guide

### System Requirements

- **Operating System**: macOS, Linux, or Windows
- **Python**: 3.13 or higher
- **Memory**: 4GB RAM minimum (8GB recommended)
- **Network**: Internet connection for cloud LLM providers

### Step 1: Install Python
Elf0 requires Python 3.13 or higher. Check your version:

```bash
python --version
# or
python3 --version
```

If you don't have Python 3.13+, download it from [python.org](https://python.org/downloads/).

### Step 2: Install uv Package Manager

Elf0 uses `uv` by Astral for fast Python package management. `uv` is a modern, blazingly fast Python package installer and resolver that's 10-100x faster than pip. It's written in Rust and provides excellent dependency resolution.

**Why we use uv:**
- ‚ö° **10-100x faster** than pip for installing packages
- üîí **Better dependency resolution** - avoids dependency conflicts
- üßπ **Clean virtual environments** - isolated, reproducible setups
- üîÑ **Drop-in pip replacement** - same commands, better performance
- üì¶ **Built-in virtual environment management**

**Installation:**

```bash
# macOS/Linux (Recommended)
curl -LsSf https://astral.sh/uv/install.sh | sh

# Windows (PowerShell)
powershell -c "irm https://astral.sh/uv/install.ps1 | iex"

# Alternative: Install via pip (slower, but works everywhere)
pip install uv

# Alternative: Install via Homebrew (macOS)
brew install uv

# Alternative: Install via pipx
pipx install uv
```

**Verify installation:**
```bash
uv --version
# Should show something like: uv 0.4.29
```

**New to uv?** Don't worry! It works just like pip but faster:
- `uv pip install package` ‚â° `pip install package`
- `uv venv` ‚â° `python -m venv`
- `uv run command` ‚â° `python command` (but with auto-dependency management)

### Step 3: Clone and Install Elf0
```bash
git clone https://github.com/emson/elf0.git
cd elf
uv venv
source .venv/bin/activate  # On Windows: .venv\Scripts\activate
uv pip install -e .
```

### Step 4: Configure API Keys

Elf0 supports multiple LLM providers. Choose one:

#### Option A: OpenAI (Recommended for beginners)
1. Get an API key from [OpenAI Platform](https://platform.openai.com/api-keys)
2. Set the environment variable:
   ```bash
   export OPENAI_API_KEY="sk-your-key-here"
   ```

#### Option B: Anthropic (Claude)
1. Get an API key from [Anthropic Console](https://console.anthropic.com/)
2. Set the environment variable:
   ```bash
   export ANTHROPIC_API_KEY="sk-ant-your-key-here"
   ```

#### Option C: Ollama (Local, Free)
1. Install Ollama from [ollama.ai](https://ollama.ai/)
2. Download a model:
   ```bash
   ollama pull llama2
   # or
   ollama pull codellama
   ```
3. No API key needed! Ollama runs locally.

### Step 5: Verify Installation
```bash
# Test with OpenAI/Anthropic
uv run elf0 agent specs/basic/chat_simple_v1.yaml --prompt "Hello, Elf0!"

# Test with Ollama (archived specs available)
uv run elf0 agent specs/basic/chat_simple_v1.yaml --prompt "Hello, Elf0!"
```

---

## üèÉ‚Äç‚ôÄÔ∏è Your First Workflow

Let's understand what just happened by examining a simple workflow:

### The Basic Chat Workflow (`specs/basic/chat_simple_v1.yaml`)
```yaml
name: basic_chat
description: Simple AI chat using Claude

llms:
  claude:
    type: anthropic
    model_name: claude-3-5-haiku-latest
    temperature: 0.7

workflow:
  type: sequential
  nodes:
    - id: chat_step
      kind: agent
      ref: claude
      stop: true
      config:
        prompt: |
          You are a helpful AI assistant. Respond to the user's request clearly and concisely.
          
          User request: {input}
```

**What this does:**
1. **Defines an LLM**: Uses Anthropic's Claude with specific settings
2. **Creates a workflow**: Sequential workflow with one step
3. **Sets up a node**: An "agent" node that processes user input
4. **Configures the prompt**: Instructions for the AI + user input placeholder
5. **Stops execution**: `stop: true` ends the workflow after this step

### Running Workflows

```bash
# Basic usage
uv run elf0 agent specs/basic/chat_simple_v1.yaml --prompt "Your message here"

# Save output to file
uv run elf0 agent specs/basic/chat_simple_v1.yaml --prompt "Write a story" --output story.md

# Use verbose mode to see what's happening
uv run elf0 --verbose agent specs/basic/chat_simple_v1.yaml --prompt "Hello"

# Interactive mode for conversations
uv run elf0 prompt specs/basic/chat_simple_v1.yaml
```

### The Magic of File References

Elf0's killer feature is automatic file inclusion using `@my/path/filename.ext` syntax:

```bash
# Automatically include file contents in your prompt
uv run elf0 agent specs/basic/chat_simple_v1.yaml --prompt "Explain this code @src/elf0/cli.py"

# Reference multiple files
uv run elf0 agent specs/basic/chat_simple_v1.yaml --prompt "Compare @file1.py and @file2.py"

# Works in interactive mode too
uv run elf0 prompt specs/basic/chat_simple_v1.yaml
üí¨ Prompt: Review @README.md and suggest improvements
```

The files are automatically read and included as context - no manual copy/paste needed!

---

## üñ•Ô∏è CLI Reference

Elf0 provides a comprehensive command-line interface for executing and managing AI workflows.

### Basic Usage
```bash
uv run elf0 [OPTIONS] COMMAND [ARGS]...
```

### Global Options
| Option | Description |
|--------|-------------|
| `--verbose`, `-v` | Enable verbose logging output (shows detailed logs from Elf0 core and HTTP libraries) |
| `--help` | Show help message and exit |

### Commands Overview

#### `agent` - Execute Workflows
Execute an agent workflow defined in YAML:

```bash
uv run elf0 agent <spec_file> [OPTIONS]
```

**Options:**
- `--prompt TEXT` - User prompt to process
- `--prompt_file PATH` - Markdown (.md) or XML (.xml) file containing the prompt  
- `--context PATH` - Context file(s) to include (use multiple times or comma-separated)
- `--output PATH` - Save result to file instead of displaying
- `--session-id TEXT` - Session identifier for stateful runs (default: "session")

**Examples:**
```bash
# Basic usage
uv run elf0 agent specs/basic/chat_simple_v1.yaml --prompt "Explain quantum computing"

# Use prompt file
uv run elf0 agent specs/basic/chat_simple_v1.yaml --prompt_file my_prompt.md

# Include context files
uv run elf0 agent specs/basic/chat_simple_v1.yaml --prompt "Analyze this" --context config.yaml --context data.csv

# Save output to file
uv run elf0 agent specs/basic/chat_simple_v1.yaml --prompt "Write documentation" --output docs.md

# Verbose mode for debugging
uv run elf0 --verbose agent specs/basic/chat_simple_v1.yaml --prompt "Debug this workflow"
```

#### `prompt` - Interactive Sessions
Start an interactive conversation with a workflow agent:

```bash
uv run elf0 prompt <spec_file> [OPTIONS]
```

**Options:**
- `--session-id TEXT` - Session identifier for the conversation (default: "interactive_session")

**Examples:**
```bash
# Start interactive session
uv run elf0 prompt specs/basic/chat_simple_v1.yaml

# Custom session ID
uv run elf0 prompt specs/basic/chat_simple_v1.yaml --session-id my_session
```

**Interactive Commands:**
- Type your prompt and press Enter twice to send
- `/send` - Send the current prompt
- `/exit`, `/quit`, `/bye` - Exit the session
- `@filename.ext` - Include file contents in your prompt

#### `improve yaml` - Workflow Optimization
Improve and optimize YAML workflow specifications using AI:

```bash
uv run elf0 improve yaml <spec_file> [OPTIONS]
```

**Options:**
- `--output PATH`, `-o PATH` - Save improved YAML to file (default: `<original>_improved.yaml`)
- `--prompt TEXT` - Custom improvement guidance (supports @file references)
- `--session-id TEXT` - Session identifier for improvement run (default: "improve_session")

**Examples:**
```bash
# Basic improvement
uv run elf0 improve yaml specs/my_workflow.yaml

# Custom output file
uv run elf0 improve yaml specs/my_workflow.yaml --output optimized_workflow.yaml

# Specific improvement guidance
uv run elf0 improve yaml specs/my_workflow.yaml --prompt "Focus on making prompts more specific"

# Use reference patterns
uv run elf0 improve yaml specs/my_workflow.yaml --prompt "Follow patterns from @examples/best_workflow.yaml"
```

#### `list-specs` - Discover Workflows
List all available YAML workflow specification files:

```bash
uv run elf0 list-specs
```

Shows all `.yaml` and `.yml` files in the `./specs` directory with their descriptions.

### Advanced Usage Patterns

#### File References with @ Syntax
Use `@path/filename.ext` anywhere in prompts to automatically include file contents:

```bash
# Single file reference
uv run elf0 agent specs/basic/chat_simple_v1.yaml --prompt "Review this code @src/elf0/cli.py"

# Multiple file references  
uv run elf0 agent specs/basic/chat_simple_v1.yaml --prompt "Compare @file1.py and @file2.py"

# In improvement guidance
uv run elf0 improve yaml specs/basic/chat_simple_v1.yaml --prompt "Use patterns from @specs/examples/claude_code_example.yaml"
```

#### Output Redirection
Control where logs and output go:

```bash
# Output to file, errors to stderr
uv run elf0 agent workflow.yaml --prompt "Generate report" > report.txt

# Verbose logs to file, output to stdout  
uv run elf0 --verbose agent workflow.yaml --prompt "Debug" 2> debug.log

# Both output and logs to files
uv run elf0 agent workflow.yaml --prompt "Process" > output.txt 2> logs.txt

# Pipe output while preserving error logs
uv run elf0 agent workflow.yaml --prompt "Generate" | grep "important"
```

#### Session Management
Use session IDs to maintain conversation context:

```bash
# Different sessions for different tasks
uv run elf0 prompt specs/chat.yaml --session-id "project_alpha"
uv run elf0 prompt specs/chat.yaml --session-id "project_beta"

# Continue previous agent session
uv run elf0 agent specs/workflow.yaml --prompt "Continue from before" --session-id "my_project"
```

---

## üß† Core Concepts

### Workflows
A **workflow** is a sequence of AI agents and tools working together. Think of it like a recipe:
1. Take user input
2. Process it with AI Agent A
3. Pass the result to Tool B  
4. Process with AI Agent C
5. Return final result

### Nodes
**Nodes** are the building blocks of workflows:
- **Agent nodes**: AI models that process text (OpenAI, Anthropic, Ollama)
- **Tool nodes**: Custom Python functions for data processing
- **MCP nodes**: External tools via Model Context Protocol
- **Claude Code nodes**: AI-powered code generation, analysis, and modification

### Edges
**Edges** connect nodes together, defining the flow of data:
- **Sequential**: Nodes run one after another
- **Conditional**: Route based on conditions (if/then logic)
- **Parallel**: Run multiple nodes simultaneously

### YAML Structure
```yaml
name: my_workflow
description: What this workflow does

# Define your AI models
llms:
  llm_model:
    type: openai
    model_name: gpt-4.1-mini
    temperature: 0.7

# Define your workflow steps  
workflow:
  type: sequential
  nodes:
    - id: step1
      kind: agent
      ref: llm_model
      config:
        prompt: "Your instructions here. User input: {input}"
```

---

## üìã Common Use Cases

### 1. Content Generation
```bash
# Blog post generation
uv run elf0 agent specs/content/content_basic_v1.yaml --prompt "Write a blog post about sustainable technology"

# LinkedIn post generation
uv run elf0 agent specs/content/linkedin_post.yaml --prompt "Create a LinkedIn post about my new AI project"

# Twitter/X post generation
uv run elf0 agent specs/content/twitter_post.yaml --prompt "Write a tweet about the benefits of renewable energy"

# Code documentation
uv run elf0 agent specs/basic/chat_simple_v1.yaml --prompt "Document this code @src/api.py"

# Meeting summaries  
uv run elf0 agent specs/basic/chat_simple_v1.yaml --prompt "Summarize this meeting transcript @meeting.txt"
```

### 2. Code Analysis
```bash
# Code review
uv run elf0 agent specs/basic/reasoning_structured_v1.yaml --prompt "Review this code for bugs and improvements @main.py"

# Security audit
uv run elf0 agent specs/basic/reasoning_structured_v1.yaml --prompt "Check this code for security vulnerabilities @auth.py"

# Performance optimization
uv run elf0 agent specs/basic/reasoning_structured_v1.yaml --prompt "Suggest performance improvements for @slow_function.py"
```

### 3. Data Processing
```bash
# Note: Python function examples are archived. Use archive directory:
# Text analysis (archived)
uv run elf0 list-specs archive  # See available archived workflows

# Basic data analysis
uv run elf0 agent specs/basic/reasoning_structured_v1.yaml --prompt "Analyze this data @data.csv"

# Content processing
uv run elf0 agent specs/content/content_basic_v1.yaml --prompt "Process and summarize @report.txt"
```

### 4. Multi-step Workflows & Utilities
```bash
# Create new workflows using AI
uv run elf0 agent specs/utils/agent_creator.yaml --prompt "Create a workflow for code review"

# Optimize existing workflows
uv run elf0 agent specs/utils/agent_optimizer.yaml --prompt "Improve this workflow @specs/basic/chat_simple_v1.yaml"

# Advanced prompt optimization
uv run elf0 agent specs/utils/prompt_optimizer.yaml --prompt "Optimize prompts for code generation"

# AI-powered code generation with Claude Code
uv run elf0 agent specs/examples/claude_code_example.yaml --prompt "Create a REST API with authentication"

# Workflow simulation and testing
uv run elf0 agent specs/utils/agent_simulation.yaml --prompt "Simulate a customer service scenario"
```

---

## üöÄ Advanced Features

### Interactive Mode
Start conversations with any workflow:

```bash
uv run elf0 prompt specs/basic/chat_simple_v1.yaml
üí¨ Prompt: Hello, how are you?
üí¨ Prompt: Analyze this file @config.yaml  
üí¨ Prompt: exit
```

### Self-Improving Workflows
Let AI improve your workflows automatically:

```bash
# Analyze and improve any workflow
uv run elf0 improve yaml specs/basic/chat_simple_v1.yaml

# Custom improvement guidance
uv run elf0 improve yaml specs/basic/chat_simple_v1.yaml --prompt "Make prompts more specific"

# Use reference patterns
uv run elf0 improve yaml specs/basic/chat_simple_v1.yaml --prompt "Follow patterns from @specs/examples/claude_code_example.yaml"

# Use dedicated optimizer workflow for advanced optimization
uv run elf0 agent specs/utils/agent_optimizer.yaml --prompt "Optimize this workflow @specs/basic/chat_simple_v1.yaml"
```

### Python Function Integration
Create custom tools using Python functions:

```python
# src/tools/my_tools.py
def process_text(state, text_input):
    """Custom text processing function."""
    processed = text_input.upper()
    return {"output": f"Processed: {processed}"}
```

```yaml
# In your workflow YAML
functions:
  text_processor:
    type: python
    name: text_processor
    entrypoint: src.tools.my_tools.process_text

workflow:
  nodes:
    - id: process
      kind: tool
      ref: text_processor
```

### Claude Code Integration
Use Claude Code SDK for AI-powered code generation, analysis, and modification:
**NB: You will need the Claude API keys set up for this**

```bash
# Generate code from requirements
uv run elf0 agent specs/examples/claude_code_example.yaml --prompt "Create a Python calculator function"

# Self-improvement workflow for Elf0 platform
uv run elf0 agent specs/examples/claude_code_self_improvement.yaml --prompt "Add better error handling to Elf0 workflows"
```

**Claude Code Node Types:**
- `generate_code`: Create new code from requirements
- `analyze_code`: Review code for quality, security, and performance
- `modify_code`: Improve existing code with specific changes
- `chat`: General conversation with code-aware AI

```yaml
# Example Claude Code node in workflow
nodes:
  - id: code_generator
    kind: claude_code
    config:
      task: "generate_code"
      prompt: "Create a Python function based on: {input}"
      output_format: "text"
      tools: ["filesystem", "bash"]
      temperature: 0.2
```

### MCP (Model Context Protocol) Integration
Connect to external tools and services:

```bash
# Note: MCP examples are archived. Access them via archive:
uv run elf0 list-specs archive  # See MCP workflow examples

# Example MCP usage (from archive):
# uv run elf0 agent specs/archive/mcp_workflow.yaml --prompt "Calculate 15 + 30"
# uv run elf0 agent specs/archive/simple_mcp.yaml --prompt "Use filesystem tools"
```

### Multiple LLM Providers
Use different AI models in the same workflow:

```yaml
llms:
  fast_model:
    type: openai
    model_name: gpt-4.1-mini
    temperature: 0.3
    
  smart_model:
    type: anthropic
    model_name: claude-sonnet-4
    temperature: 0.7
    
  local_model:
    type: ollama
    model_name: llama3
    temperature: 0.5

workflow:
  nodes:
    - id: draft
      kind: agent
      ref: fast_model  # Quick draft
    - id: refine  
      kind: agent
      ref: smart_model  # Detailed refinement
```

---

## üîó File Reference System

Elf0's `@filename.ext` syntax automatically includes file contents in prompts:

### Basic Usage
```bash
# Single file
uv run elf0 agent specs/basic/chat_simple_v1.yaml --prompt "Explain @main.py"

# Multiple files  
uv run elf0 agent specs/basic/chat_simple_v1.yaml --prompt "Compare @file1.py and @file2.py"

# Mixed with regular text
uv run elf0 agent specs/basic/chat_simple_v1.yaml --prompt "Review @code.py and suggest improvements based on @guidelines.md"
```

### Supported File Types
- **Code**: `.py`, `.js`, `.ts`, `.java`, `.cpp`, etc.
- **Text**: `.txt`, `.md`, `.rst`, `.log`  
- **Config**: `.yaml`, `.yml`, `.json`, `.toml`, `.ini`
- **Data**: `.csv`, `.xml` (text-based files)

### Best Practices
- **Keep files reasonably sized** (< 10KB for best results)
- **Use descriptive filenames** (`user_auth.py` vs `utils.py`)
- **Combine with context** (`--context` flag for additional files)
- **Reference documentation** (`@README.md`, `@CHANGELOG.md`)

### Examples
```bash
# Code review with context
uv run elf0 agent specs/basic/reasoning_structured_v1.yaml \
  --prompt "Review @api.py for security issues" \
  --context requirements.txt --context .env.example

# Documentation generation
uv run elf0 agent specs/content/content_basic_v1.yaml \
  --prompt "Create API docs for @server.py based on @api_spec.yaml"

# Test generation  
uv run elf0 agent specs/basic/reasoning_structured_v1.yaml \
  --prompt "Write unit tests for @calculator.py following patterns in @test_example.py"
```

---

## üîí Security & Safety Considerations

### ‚ö†Ô∏è Important Security Warnings

**Elf0 is experimental software that can execute arbitrary code and interact with your system. Use with extreme caution.**

#### Potential Risks:
- **File System Access**: Workflows can read, write, and delete files
- **Network Requests**: External API calls and web requests  
- **Code Execution**: Custom Python functions and MCP servers
- **System Commands**: Potential shell command execution
- **Data Exposure**: Sensitive data may be sent to LLM providers

#### Best Practices:
```bash
# 1. Always review workflows before running
cat specs/workflow.yaml  # Inspect the workflow

# 2. Test in isolated environments  
docker run --rm -it python:3.13  # Use containers
python -m venv test_env           # Separate virtual environments

# 3. Use restricted permissions
chmod 644 sensitive_files/        # Read-only important files
chattr +i important_config        # Immutable critical configs (Linux)

# 4. Monitor workflow execution
uv run elf0 --verbose agent workflow.yaml  # Watch what happens

# 5. Backup before experimentation
cp -r project/ project_backup/    # Backup your work
```

#### What Workflows Can Do:
- **Read any accessible file** on your system
- **Write/modify files** with your user permissions  
- **Make network requests** to external services
- **Execute Python code** defined in workflows
- **Start external processes** via MCP servers
- **Access environment variables** including API keys

#### Red Flags - Never Run Workflows That:
- Come from untrusted sources
- Use `os.system()` or `subprocess` calls
- Access sensitive directories (`/etc`, `~/.ssh`, etc.)
- Make unexpected network requests
- Request elevated permissions
- Modify system configurations

#### Data Privacy:
- **LLM Providers**: Your prompts/data are sent to OpenAI, Anthropic, etc.
- **Local Processing**: Ollama keeps data local but uses system resources
- **File Contents**: `@file.txt` syntax uploads file contents to LLMs
- **Logging**: Workflow data may be logged locally

### Safe Usage Guidelines

```bash
# Create a dedicated Elf0 workspace
mkdir ~/elf0_workspace
cd ~/elf0_workspace
git clone https://github.com/emson/elf0.git
cd elf0

# Use a dedicated Python environment
uv venv elf0_env
source elf0_env/bin/activate

# Set up minimal API keys (avoid using production keys)
export OPENAI_API_KEY="sk-test-key-here"  # Use test/development keys

# Test with safe, simple workflows first
uv run elf0 agent specs/basic_chat.yaml --prompt "Hello world"
```

---

## üõ† Troubleshooting

### Common Issues

#### 1. "Command not found: elf"
```bash
# Make sure you're in the virtual environment
source .venv/bin/activate  # macOS/Linux
.venv\Scripts\activate     # Windows

# Verify installation
uv pip list | grep elf
```

#### 2. "API key not found" 
```bash
# Check your environment variables
echo $OPENAI_API_KEY
echo $ANTHROPIC_API_KEY

# Set them properly
export OPENAI_API_KEY="your-key-here"

# Or use a .env file in the project root
echo "OPENAI_API_KEY=your-key-here" > .env
```

#### 3. "Module not found" errors
```bash
# Reinstall in development mode
uv pip install -e .

# Or install dependencies
uv pip install -r requirements.txt
```

#### 4. "Workflow file not found"
```bash
# Check the file exists
ls specs/basic_chat.yaml

# Use full path if needed
uv run elf0 agent /full/path/to/specs/basic_chat.yaml --prompt "test"
```

#### 5. Ollama connection issues
```bash
# Make sure Ollama is running
ollama list

# Start Ollama service
ollama serve

# Test with a simple model
ollama run llama2 "Hello"
```

#### 6. uv package manager issues
```bash
# uv command not found
# Make sure uv is in your PATH - restart your terminal after installation
echo $PATH | grep -i uv

# Reinstall uv if needed
curl -LsSf https://astral.sh/uv/install.sh | sh

# Alternative: Use pip fallback
pip install -e .  # Instead of uv pip install -e .

# Clear uv cache if having dependency issues
uv cache clean

# Check uv configuration
uv --help
```

### Platform-Specific Issues

#### Windows
- Use `py` instead of `python` if you have multiple Python versions
- Use PowerShell or Command Prompt, not Git Bash for installation
- Path separators: use forward slashes `/` in file paths

#### macOS
- Install Xcode Command Line Tools: `xcode-select --install`
- Use Homebrew for Python if needed: `brew install python@3.13`

#### Linux  
- Install Python dev headers: `sudo apt-get install python3-dev`
- Some distributions need: `sudo apt-get install build-essential`

### Getting Help

1. **Check the examples**: Look in `specs/examples/` for working workflows
2. **Use verbose mode**: `uv run elf0 --verbose` to see detailed logs
3. **Check the issues**: [GitHub Issues](https://github.com/emson/elf/issues) 
4. **Start a discussion**: [GitHub Discussions](https://github.com/emson/elf/discussions)

---

## üìÇ Project Structure

Understanding where files go helps you organize your workflows:

```
elf0/
‚îú‚îÄ‚îÄ specs/                    # Workflow definitions (organized by category)
‚îÇ   ‚îú‚îÄ‚îÄ basic/               # Simple, foundational workflows
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ chat_simple_v1.yaml      # Basic chat workflow
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ reasoning_structured_v1.yaml  # Structured reasoning
‚îÇ   ‚îú‚îÄ‚îÄ content/             # Content generation workflows
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ content_basic_v1.yaml    # General content creation
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ linkedin_post.yaml       # LinkedIn posts
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ twitter_post.yaml        # Twitter/X posts
‚îÇ   ‚îú‚îÄ‚îÄ utils/               # Utility workflows for workflow management
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ agent_creator.yaml       # Create new workflows
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ agent_optimizer.yaml     # Optimize workflows
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ prompt_optimizer.yaml    # Optimize prompts
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ agent_simulation.yaml    # Simulate scenarios
‚îÇ   ‚îú‚îÄ‚îÄ examples/            # Advanced examples
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ claude_code_example.yaml
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ claude_code_self_improvement.yaml
‚îÇ   ‚îî‚îÄ‚îÄ archive/             # Legacy/archived workflows
‚îÇ       ‚îî‚îÄ‚îÄ (many legacy workflows)
‚îú‚îÄ‚îÄ src/elf0/               # Elf0 source code
‚îú‚îÄ‚îÄ mcp/                    # MCP server configurations
‚îî‚îÄ‚îÄ your_workflows/         # Put your custom workflows here
```

### Creating Your Own Workflows

1. **Start with an example**: Copy from `specs/basic/` or use the AI creator
2. **Modify gradually**: Change prompts, models, add steps
3. **Test frequently**: Run after each change
4. **Use version control**: Git track your workflow evolution

```bash
# Copy and customize
cp specs/basic/chat_simple_v1.yaml my_workflow.yaml

# Or create with AI assistance
uv run elf0 agent specs/utils/agent_creator.yaml --prompt "Create a workflow for code documentation"

# Edit with your favorite editor
code my_workflow.yaml  # VS Code
vim my_workflow.yaml   # Vim
nano my_workflow.yaml  # Nano

# Test your changes
uv run elf0 agent my_workflow.yaml --prompt "test"

# Optimize with AI
uv run elf0 agent specs/utils/agent_optimizer.yaml --prompt "Improve this workflow @my_workflow.yaml"
```

---

## üéØ Examples Gallery

### Simple Examples (Start Here)

#### Basic Chat
```bash
uv run elf0 agent specs/basic/chat_simple_v1.yaml --prompt "Explain photosynthesis"
```

#### Structured Reasoning
```bash
uv run elf0 agent specs/basic/reasoning_structured_v1.yaml --prompt "Analyze the pros and cons of renewable energy"
```

#### Code Analysis  
```bash
uv run elf0 agent specs/basic/reasoning_structured_v1.yaml --prompt "Review this code @example.py"
```

#### Content Generation
```bash
# Blog content
uv run elf0 agent specs/content/content_basic_v1.yaml --prompt "Write about artificial intelligence trends"

# LinkedIn post
uv run elf0 agent specs/content/linkedin_post.yaml --prompt "Create a post about remote work benefits"

# Twitter/X post
uv run elf0 agent specs/content/twitter_post.yaml --prompt "Share insights about machine learning"
```

### Intermediate Examples

#### Interactive Session
```bash
uv run elf0 prompt specs/basic/chat_simple_v1.yaml
üí¨ Prompt: Help me debug @buggy_code.py
üí¨ Prompt: Now write tests for the fixed version
üí¨ Prompt: exit
```

#### Workflow Creation & Optimization
```bash
# Create new workflows with AI assistance
uv run elf0 agent specs/utils/agent_creator.yaml --prompt "Create a workflow for automated testing"

# Optimize existing workflows
uv run elf0 agent specs/utils/agent_optimizer.yaml --prompt "Improve this workflow @specs/basic/chat_simple_v1.yaml"

# Advanced prompt optimization
uv run elf0 agent specs/utils/prompt_optimizer.yaml --prompt "Optimize prompts for better code generation"
```

#### Workflow Simulation & Testing
```bash
# Simulate complex scenarios
uv run elf0 agent specs/utils/agent_simulation.yaml --prompt "Simulate a customer support interaction"
```

### Advanced Examples

#### Self-Improvement
```bash
uv run elf0 improve yaml specs/basic/chat_simple_v1.yaml --prompt "Make this workflow better for code review"
```

#### Claude Code Integration
```bash
# AI-powered code generation and improvement
uv run elf0 agent specs/examples/claude_code_example.yaml --prompt "Create a REST API with authentication"

# Self-evolving AI platform capabilities  
uv run elf0 agent specs/examples/claude_code_self_improvement.yaml --prompt "Add logging capabilities to Elf0 workflows"
```

#### Discovering More Examples
```bash
# List all available workflow categories
uv run elf0 list-specs

# Explore archived workflows (including legacy examples)
uv run elf0 list-specs archive

# Create your own based on existing patterns
uv run elf0 agent specs/utils/agent_creator.yaml --prompt "Create a workflow based on @specs/content/linkedin_post.yaml for newsletter generation"
```

---

## ü§ù Contributing

We welcome contributions! Here's how to get involved:

### Quick Contributions
- **Report bugs**: [Create an issue](https://github.com/emson/elf/issues/new)
- **Suggest features**: [Start a discussion](https://github.com/emson/elf/discussions)
- **Improve docs**: Edit README or add examples
- **Share workflows**: Submit your useful workflows

### Development Setup
```bash
git clone https://github.com/emson/elf.git
cd elf
uv venv                    # Create virtual environment (much faster than python -m venv)
source .venv/bin/activate  # Activate environment
uv pip install -e .       # Install Elf0 in development mode (faster than pip)

# Install development dependencies
uv pip install pytest ruff mypy

# Run tests
pytest

# Run linting
ruff check src/
mypy src/
```

**Note:** All `uv pip` commands can be replaced with regular `pip` commands if you prefer, but `uv` will be significantly faster for dependency resolution and installation.

### Areas We Need Help
- **New workflow examples** for different use cases
- **Documentation improvements** for clarity
- **MCP server integrations** for popular tools
- **Performance optimizations** for large workflows
- **Platform testing** (Windows, Linux, different Python versions)

### Code Style
- Follow PEP 8 conventions
- Use type hints for all functions
- Add tests for new features
- Update documentation

---

## üìÑ License & Legal Disclaimers

Elf0 is licensed under the [Apache License 2.0](LICENSE). This means you can freely use, modify, and distribute this software, even for commercial purposes, as long as you include the original license and copyright notice.

### Legal Disclaimers

**DISCLAIMER OF WARRANTIES**: This software is provided "AS IS" without warranty of any kind, express or implied, including but not limited to the warranties of merchantability, fitness for a particular purpose, and non-infringement.

**LIMITATION OF LIABILITY**: In no event shall the authors, copyright holders, or contributors be liable for any claim, damages, or other liability, whether in an action of contract, tort, or otherwise, arising from, out of, or in connection with the software or the use or other dealings in the software.

**USER RESPONSIBILITY**: You are solely responsible for:
- Reviewing workflow files before execution
- Ensuring appropriate security measures  
- Protecting sensitive data and systems
- Complying with applicable laws and regulations
- Any consequences of using this experimental software

**EXPERIMENTAL SOFTWARE**: This is beta/experimental software under active development. Features may change, break, or be removed without notice. Use in production environments is strongly discouraged.

**NO SUPPORT GUARANTEE**: While we appreciate community contributions, there is no guarantee of support, maintenance, or updates to this software.

## üôè Acknowledgments

- Built with [LangGraph](https://github.com/langchain-ai/langgraph) for workflow orchestration
- Powered by [Rich](https://github.com/Textualize/rich) for beautiful terminal output  
- Uses [uv](https://github.com/astral-sh/uv) by [Astral](https://astral.sh/) for blazingly fast Python package management
- Supports [MCP](https://modelcontextprotocol.io/) for tool integration
- Inspired by NVIDIA's AgentIQ framework for AI workflow design patterns

---

**Ready to build your first AI workflow?** Start with the [Quick Start](#-quick-start-5-minutes) section above! üöÄ
