# Location: workflows/basic_chat.yaml
version: "0.1"
description: "Basic chat workflow that takes user input and returns a response"
runtime: "langgraph"

# LLM definitions
llms:
  chat_llm:
    type: "anthropic"
    model_name: "claude-sonnet-4-20250514"
    # model_name: "claude-3-5-haiku-20241022"
    temperature: 0.7
    params:
      max_tokens: 1000
      # Retry configuration for handling API overload
      max_retries: 3
      retry_delay: 1.0
      max_retry_delay: 30.0
      retry_backoff_factor: 2.0
      system_prompt: |
        You are a friendly assistant who always ends a conversation with an emoji.

# No retrievers, memory or functions needed for basic chat
retrievers: {}
memory: {}
functions: {}

# Workflow definition
workflow:
  type: "sequential"
  nodes:
    - id: "chat_step"
      kind: "agent"
      ref: "chat_llm"
      stop: true
  edges: []