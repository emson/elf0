# Location: workflows/basic_chat.yaml
version: "0.1"
description: "Basic chat workflow that takes user input and returns a response"
runtime: "langgraph"

# LLM definitions
llms:
  chat_llm:
    type: "anthropic"
    model_name: "claude-3-5-haiku-latest"
    temperature: 0.7
    params:
      max_tokens: 1000
      system_prompt: |
        You are a friendly assistant who always ends a conversation with an emoji.

# No retrievers, memory or functions needed for basic chat
retrievers: {}
memory: {}
functions: {}

# Workflow definition
workflow:
  type: "sequential"
  nodes:
    - id: "chat_step"
      kind: "agent"
      ref: "chat_llm"
      stop: true
  edges: []