# Example workflow demonstrating MCP (Model Context Protocol) tool integration
version: "0.1"
description: "A workflow that demonstrates how to use MCP tools alongside LLM agents"
runtime: "langgraph"

# LLM configurations
llms:
  analyzer_llm:
    type: "openai"
    model_name: "gpt-4.1-mini"
    temperature: 0.3
    params:
      max_tokens: 500

  summarizer_llm:
    type: "openai" 
    model_name: "gpt-4.1-mini"
    temperature: 0.7
    params:
      max_tokens: 300

# No MCP function definitions needed - use MCP nodes directly

# Workflow definition
workflow:
  type: "custom_graph"
  nodes:
    # Initial analysis by LLM
    - id: "input_analyzer"
      kind: "agent"
      ref: "analyzer_llm"
      config:
        prompt: |
          Analyze the following input and determine what type of processing is needed:
          
          Input: {input}
          
          Please categorize this input as one of:
          - "math" (if it contains mathematical expressions or calculations)
          - "data" (if it contains data that needs processing)
          - "text" (if it needs text analysis)
          
          Respond with just the category name.
      stop: false

    # Extract parameters from the math expression
    - id: "math_extractor"
      kind: "agent"
      ref: "analyzer_llm"
      config:
        prompt: |
          Extract the mathematical operation from this input: {input}
          
          Parse the expression and return ONLY a JSON object with these exact keys:
          - a: first number (as a number, not string)
          - b: second number (as a number, not string)  
          - operation: one of "add", "subtract", "multiply", "divide"
          
          Examples:
          - "15 + 27" should return: {{"a": 15, "b": 27, "operation": "add"}}
          - "50 - 20" should return: {{"a": 50, "b": 20, "operation": "subtract"}}
          - "8 * 6" should return: {{"a": 8, "b": 6, "operation": "multiply"}}
          - "100 / 4" should return: {{"a": 100, "b": 4, "operation": "divide"}}
          
          Return ONLY the JSON object, no other text.
      stop: false

    # MCP node for mathematical calculations
    - id: "math_tool"
      kind: "mcp"
      config:
        server:
          command: ["python", "mcp/calculator/server.py"]
        tool: "calculate"
        parameters:
          a: "${state.json.a}"
          b: "${state.json.b}"
          operation: "${state.json.operation}"
      stop: false

    # MCP node for data processing  
    - id: "data_tool"
      kind: "agent"
      ref: "analyzer_llm"
      config:
        prompt: "Process this data: ${state.input}"
      stop: false

    # MCP node for text analysis
    - id: "text_tool"
      kind: "agent"
      ref: "analyzer_llm"
      config:
        prompt: "Analyze this text: ${state.input}"
      stop: false

    # Final summarization by LLM
    - id: "result_summarizer"
      kind: "agent"
      ref: "summarizer_llm"
      config:
        prompt: |
          Please provide a clear and concise summary of the calculation that was just performed.
          
          Original request: {input}
          
          Summarize what calculation was done and what the result was.
      stop: true

  # Conditional routing based on input analysis
  edges:
    # Route from analyzer to appropriate tool
    - source: "input_analyzer"
      target: "math_extractor"
      condition: "state.get('output', '').strip().lower() == 'math'"

    - source: "input_analyzer"
      target: "data_tool"
      condition: "state.get('output', '').strip().lower() == 'data'"

    - source: "input_analyzer"
      target: "text_tool"
      condition: "state.get('output', '').strip().lower() == 'text'"

    # Route from math extractor to math tool
    - source: "math_extractor"
      target: "math_tool"

    # Route from tools to summarizer
    - source: "math_tool"
      target: "result_summarizer"

    - source: "data_tool"
      target: "result_summarizer"

    - source: "text_tool"
      target: "result_summarizer"
