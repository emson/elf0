# üßù ELF - sElf Improving AI Workflows

**Build powerful AI agent workflows using simple YAML files. No complex coding required.**

ELF (sElf-improving Llm-powered workFlows) lets you create multi-step AI workflows by describing what you want in YAML. Chain together different AI models, integrate with external tools, and even use AI to improve your workflows automatically.

```bash
# Simple AI workflow in one command
uv run elf agent specs/basic_chat.yaml --prompt "Explain quantum computing in simple terms"

# Reference files automatically with @filename.ext syntax  
uv run elf agent specs/basic_chat.yaml --prompt "Review this code @src/elf/cli.py and suggest improvements"

# Let AI improve your workflows
uv run elf improve yaml specs/my_workflow.yaml --prompt "Make this workflow more efficient"
```

## ‚ö° Quick Start (5 minutes)

Get up and running with your first AI workflow in 5 minutes:

### 1. Prerequisites
- **Python 3.13+** ([Download here](https://python.org/downloads/))
- **uv package manager** by Astral ([Install guide](https://docs.astral.sh/uv/getting-started/installation/)) - A blazingly fast Python package manager that replaces pip/conda
- **An API key** from [OpenAI](https://platform.openai.com/api-keys), [Anthropic](https://console.anthropic.com/), or use [Ollama](https://ollama.ai/) locally

### 2. Install ELF
```bash
git clone https://github.com/emson/elf.git
cd elf
uv venv
source .venv/bin/activate  # On Windows: .venv\Scripts\activate
uv pip install -e .
```

### 3. Set up your API keys
Configure your environment using the provided template:

```bash
# Copy the environment template
cp .env.example .env

# Edit .env with your actual API keys
# The file contains detailed instructions and all supported providers
```

**Quick setup for common providers:**
```bash
# For OpenAI (recommended for beginners)
export OPENAI_API_KEY="your-api-key-here"

# OR for Anthropic (Claude)
export ANTHROPIC_API_KEY="your-api-key-here"

# OR use Ollama locally (no API key needed)
# Install Ollama from https://ollama.ai/ and run: ollama pull llama2
```

**Supported LLM providers:**
- **OpenAI**: GPT-4, GPT-3.5, etc. - Get API key from [platform.openai.com](https://platform.openai.com/api-keys)
- **Anthropic**: Claude models - Get API key from [console.anthropic.com](https://console.anthropic.com/)
- **DeepSeek**: Advanced models - Get API key from [platform.deepseek.com](https://platform.deepseek.com/)
- **Ollama**: Local models (free) - No API key required, install from [ollama.ai](https://ollama.ai/)

### 4. Run your first workflow
```bash
uv run elf agent specs/basic_chat.yaml --prompt "Write a haiku about programming"
```

**üéâ It works!** You should see a beautiful haiku generated by AI. 

---

## üì¶ Complete Installation Guide

### System Requirements

- **Operating System**: macOS, Linux, or Windows
- **Python**: 3.13 or higher
- **Memory**: 4GB RAM minimum (8GB recommended)
- **Network**: Internet connection for cloud LLM providers

### Step 1: Install Python
ELF requires Python 3.13 or higher. Check your version:

```bash
python --version
# or
python3 --version
```

If you don't have Python 3.13+, download it from [python.org](https://python.org/downloads/).

### Step 2: Install uv Package Manager

ELF uses `uv` by Astral for fast Python package management. `uv` is a modern, blazingly fast Python package installer and resolver that's 10-100x faster than pip. It's written in Rust and provides excellent dependency resolution.

**Why we use uv:**
- ‚ö° **10-100x faster** than pip for installing packages
- üîí **Better dependency resolution** - avoids dependency conflicts
- üßπ **Clean virtual environments** - isolated, reproducible setups
- üîÑ **Drop-in pip replacement** - same commands, better performance
- üì¶ **Built-in virtual environment management**

**Installation:**

```bash
# macOS/Linux (Recommended)
curl -LsSf https://astral.sh/uv/install.sh | sh

# Windows (PowerShell)
powershell -c "irm https://astral.sh/uv/install.ps1 | iex"

# Alternative: Install via pip (slower, but works everywhere)
pip install uv

# Alternative: Install via Homebrew (macOS)
brew install uv

# Alternative: Install via pipx
pipx install uv
```

**Verify installation:**
```bash
uv --version
# Should show something like: uv 0.4.29
```

**New to uv?** Don't worry! It works just like pip but faster:
- `uv pip install package` ‚â° `pip install package`
- `uv venv` ‚â° `python -m venv`
- `uv run command` ‚â° `python command` (but with auto-dependency management)

### Step 3: Clone and Install ELF
```bash
git clone https://github.com/emson/elf.git
cd elf
uv venv
source .venv/bin/activate  # On Windows: .venv\Scripts\activate
uv pip install -e .
```

### Step 4: Configure API Keys

ELF supports multiple LLM providers. Choose one:

#### Option A: OpenAI (Recommended for beginners)
1. Get an API key from [OpenAI Platform](https://platform.openai.com/api-keys)
2. Set the environment variable:
   ```bash
   export OPENAI_API_KEY="sk-your-key-here"
   ```

#### Option B: Anthropic (Claude)
1. Get an API key from [Anthropic Console](https://console.anthropic.com/)
2. Set the environment variable:
   ```bash
   export ANTHROPIC_API_KEY="sk-ant-your-key-here"
   ```

#### Option C: Ollama (Local, Free)
1. Install Ollama from [ollama.ai](https://ollama.ai/)
2. Download a model:
   ```bash
   ollama pull llama2
   # or
   ollama pull codellama
   ```
3. No API key needed! Ollama runs locally.

### Step 5: Verify Installation
```bash
# Test with OpenAI/Anthropic
uv run elf agent specs/basic_chat.yaml --prompt "Hello, ELF!"

# Test with Ollama (use ollama spec)
uv run elf agent specs/examples/ollama_chat.yaml --prompt "Hello, ELF!"
```

---

## üèÉ‚Äç‚ôÄÔ∏è Your First Workflow

Let's understand what just happened by examining a simple workflow:

### The Basic Chat Workflow (`specs/basic_chat.yaml`)
```yaml
name: basic_chat
description: Simple AI chat using Claude

llms:
  claude:
    type: anthropic
    model_name: claude-3-5-haiku-latest
    temperature: 0.7

workflow:
  type: sequential
  nodes:
    - id: chat_step
      kind: agent
      ref: claude
      stop: true
      config:
        prompt: |
          You are a helpful AI assistant. Respond to the user's request clearly and concisely.
          
          User request: {input}
```

**What this does:**
1. **Defines an LLM**: Uses Anthropic's Claude with specific settings
2. **Creates a workflow**: Sequential workflow with one step
3. **Sets up a node**: An "agent" node that processes user input
4. **Configures the prompt**: Instructions for the AI + user input placeholder
5. **Stops execution**: `stop: true` ends the workflow after this step

### Running Workflows

```bash
# Basic usage
uv run elf agent specs/basic_chat.yaml --prompt "Your message here"

# Save output to file
uv run elf agent specs/basic_chat.yaml --prompt "Write a story" --output story.md

# Use verbose mode to see what's happening
uv run elf --verbose agent specs/basic_chat.yaml --prompt "Hello"

# Interactive mode for conversations
uv run elf prompt specs/basic_chat.yaml
```

### The Magic of File References

ELF's killer feature is automatic file inclusion using `@my/path/filename.ext` syntax:

```bash
# Automatically include file contents in your prompt
uv run elf agent specs/basic_chat.yaml --prompt "Explain this code @src/elf/cli.py"

# Reference multiple files
uv run elf agent specs/basic_chat.yaml --prompt "Compare @file1.py and @file2.py"

# Works in interactive mode too
uv run elf prompt specs/basic_chat.yaml
üí¨ Prompt: Review @README.md and suggest improvements
```

The files are automatically read and included as context - no manual copy/paste needed!

---

## üñ•Ô∏è CLI Reference

ELF provides a comprehensive command-line interface for executing and managing AI workflows.

### Basic Usage
```bash
uv run elf [OPTIONS] COMMAND [ARGS]...
```

### Global Options
| Option | Description |
|--------|-------------|
| `--verbose`, `-v` | Enable verbose logging output (shows detailed logs from ELF core and HTTP libraries) |
| `--help` | Show help message and exit |

### Commands Overview

#### `agent` - Execute Workflows
Execute an agent workflow defined in YAML:

```bash
uv run elf agent <spec_file> [OPTIONS]
```

**Options:**
- `--prompt TEXT` - User prompt to process
- `--prompt_file PATH` - Markdown (.md) or XML (.xml) file containing the prompt  
- `--context PATH` - Context file(s) to include (use multiple times or comma-separated)
- `--output PATH` - Save result to file instead of displaying
- `--session-id TEXT` - Session identifier for stateful runs (default: "session")

**Examples:**
```bash
# Basic usage
uv run elf agent specs/basic_chat.yaml --prompt "Explain quantum computing"

# Use prompt file
uv run elf agent specs/basic_chat.yaml --prompt_file my_prompt.md

# Include context files
uv run elf agent specs/basic_chat.yaml --prompt "Analyze this" --context config.yaml --context data.csv

# Save output to file
uv run elf agent specs/basic_chat.yaml --prompt "Write documentation" --output docs.md

# Verbose mode for debugging
uv run elf --verbose agent specs/basic_chat.yaml --prompt "Debug this workflow"
```

#### `prompt` - Interactive Sessions
Start an interactive conversation with a workflow agent:

```bash
uv run elf prompt <spec_file> [OPTIONS]
```

**Options:**
- `--session-id TEXT` - Session identifier for the conversation (default: "interactive_session")

**Examples:**
```bash
# Start interactive session
uv run elf prompt specs/basic_chat.yaml

# Custom session ID
uv run elf prompt specs/basic_chat.yaml --session-id my_session
```

**Interactive Commands:**
- Type your prompt and press Enter twice to send
- `/send` - Send the current prompt
- `/exit`, `/quit`, `/bye` - Exit the session
- `@filename.ext` - Include file contents in your prompt

#### `improve yaml` - Workflow Optimization
Improve and optimize YAML workflow specifications using AI:

```bash
uv run elf improve yaml <spec_file> [OPTIONS]
```

**Options:**
- `--output PATH`, `-o PATH` - Save improved YAML to file (default: `<original>_improved.yaml`)
- `--prompt TEXT` - Custom improvement guidance (supports @file references)
- `--session-id TEXT` - Session identifier for improvement run (default: "improve_session")

**Examples:**
```bash
# Basic improvement
uv run elf improve yaml specs/my_workflow.yaml

# Custom output file
uv run elf improve yaml specs/my_workflow.yaml --output optimized_workflow.yaml

# Specific improvement guidance
uv run elf improve yaml specs/my_workflow.yaml --prompt "Focus on making prompts more specific"

# Use reference patterns
uv run elf improve yaml specs/my_workflow.yaml --prompt "Follow patterns from @examples/best_workflow.yaml"
```

#### `list-specs` - Discover Workflows
List all available YAML workflow specification files:

```bash
uv run elf list-specs
```

Shows all `.yaml` and `.yml` files in the `./specs` directory with their descriptions.

### Advanced Usage Patterns

#### File References with @ Syntax
Use `@filename.ext` anywhere in prompts to automatically include file contents:

```bash
# Single file reference
uv run elf agent specs/basic_chat.yaml --prompt "Review this code @src/main.py"

# Multiple file references  
uv run elf agent specs/basic_chat.yaml --prompt "Compare @file1.py and @file2.py"

# In improvement guidance
uv run elf improve yaml specs/workflow.yaml --prompt "Use patterns from @examples/template.yaml"
```

#### Output Redirection
Control where logs and output go:

```bash
# Output to file, errors to stderr
uv run elf agent workflow.yaml --prompt "Generate report" > report.txt

# Verbose logs to file, output to stdout  
uv run elf --verbose agent workflow.yaml --prompt "Debug" 2> debug.log

# Both output and logs to files
uv run elf agent workflow.yaml --prompt "Process" > output.txt 2> logs.txt

# Pipe output while preserving error logs
uv run elf agent workflow.yaml --prompt "Generate" | grep "important"
```

#### Session Management
Use session IDs to maintain conversation context:

```bash
# Different sessions for different tasks
uv run elf prompt specs/chat.yaml --session-id "project_alpha"
uv run elf prompt specs/chat.yaml --session-id "project_beta"

# Continue previous agent session
uv run elf agent specs/workflow.yaml --prompt "Continue from before" --session-id "my_project"
```

---

## üß† Core Concepts

### Workflows
A **workflow** is a sequence of AI agents and tools working together. Think of it like a recipe:
1. Take user input
2. Process it with AI Agent A
3. Pass the result to Tool B  
4. Process with AI Agent C
5. Return final result

### Nodes
**Nodes** are the building blocks of workflows:
- **Agent nodes**: AI models that process text (OpenAI, Anthropic, Ollama)
- **Tool nodes**: Custom Python functions for data processing
- **MCP nodes**: External tools via Model Context Protocol
- **Claude Code nodes**: AI-powered code generation, analysis, and modification

### Edges
**Edges** connect nodes together, defining the flow of data:
- **Sequential**: Nodes run one after another
- **Conditional**: Route based on conditions (if/then logic)
- **Parallel**: Run multiple nodes simultaneously

### YAML Structure
```yaml
name: my_workflow
description: What this workflow does

# Define your AI models
llms:
  llm_model:
    type: openai
    model_name: gpt-4.1-mini
    temperature: 0.7

# Define your workflow steps  
workflow:
  type: sequential
  nodes:
    - id: step1
      kind: agent
      ref: llm_model
      config:
        prompt: "Your instructions here. User input: {input}"
```

---

## üìã Common Use Cases

### 1. Content Generation
```bash
# Blog post generation
uv run elf agent specs/basic_chat.yaml --prompt "Write a blog post about sustainable technology"

# Code documentation
uv run elf agent specs/basic_chat.yaml --prompt "Document this code @src/api.py"

# Meeting summaries  
uv run elf agent specs/basic_chat.yaml --prompt "Summarize this meeting transcript @meeting.txt"
```

### 2. Code Analysis
```bash
# Code review
uv run elf agent specs/basic_chat.yaml --prompt "Review this code for bugs and improvements @main.py"

# Security audit
uv run elf agent specs/basic_chat.yaml --prompt "Check this code for security vulnerabilities @auth.py"

# Performance optimization
uv run elf agent specs/basic_chat.yaml --prompt "Suggest performance improvements for @slow_function.py"
```

### 3. Data Processing
```bash
# Text analysis
uv run elf agent specs/examples/python_text_processor.yaml --prompt "artificial intelligence"

# File processing with custom functions
uv run elf agent specs/examples/python_calculator.yaml --prompt "Calculate 23 plus 102"

# Interactive data workflows
uv run elf agent specs/examples/python_function_test.yaml --prompt "Process data"
```

### 4. Multi-step Workflows
```bash
# Research and summarization
uv run elf agent specs/examples/prompt_chaining.yaml --prompt "Research topic: renewable energy"

# Code generation and review
uv run elf agent specs/examples/ollama_coder.yaml --prompt "Create a REST API"

# Document processing pipeline
uv run elf agent specs/examples/mcp_workflow.yaml --prompt "Process documents"
```

---

## üöÄ Advanced Features

### Interactive Mode
Start conversations with any workflow:

```bash
uv run elf prompt specs/basic_chat.yaml
üí¨ Prompt: Hello, how are you?
üí¨ Prompt: Analyze this file @config.yaml  
üí¨ Prompt: exit
```

### Self-Improving Workflows
Let AI improve your workflows automatically:

```bash
# Analyze and improve any workflow
uv run elf improve yaml specs/my_workflow.yaml

# Custom improvement guidance
uv run elf improve yaml specs/my_workflow.yaml --prompt "Make prompts more specific"

# Use reference patterns
uv run elf improve yaml specs/my_workflow.yaml --prompt "Follow patterns from @examples/best_workflow.yaml"
```

### Python Function Integration
Create custom tools using Python functions:

```python
# src/tools/my_tools.py
def process_text(state, text_input):
    """Custom text processing function."""
    processed = text_input.upper()
    return {"output": f"Processed: {processed}"}
```

```yaml
# In your workflow YAML
functions:
  text_processor:
    type: python
    name: text_processor
    entrypoint: src.tools.my_tools.process_text

workflow:
  nodes:
    - id: process
      kind: tool
      ref: text_processor
```

### Claude Code Integration
Use Claude Code SDK for AI-powered code generation, analysis, and modification:
**NB: You will need the Claude API keys set up for this**

```bash
# Generate code from requirements
uv run elf agent specs/examples/claude_code_example.yaml --prompt "Create a Python calculator function"

# Self-improvement workflow for ELF platform
uv run elf agent specs/examples/claude_code_self_improvement.yaml --prompt "Add better error handling to ELF workflows"
```

**Claude Code Node Types:**
- `generate_code`: Create new code from requirements
- `analyze_code`: Review code for quality, security, and performance
- `modify_code`: Improve existing code with specific changes
- `chat`: General conversation with code-aware AI

```yaml
# Example Claude Code node in workflow
nodes:
  - id: code_generator
    kind: claude_code
    config:
      task: "generate_code"
      prompt: "Create a Python function based on: {input}"
      output_format: "text"
      tools: ["filesystem", "bash"]
      temperature: 0.2
```

### MCP (Model Context Protocol) Integration
Connect to external tools and services:

```bash
# Run MCP-enabled workflows
uv run elf agent specs/examples/mcp_workflow.yaml --prompt "Calculate 15 + 30"

# MCP servers are started automatically
uv run elf agent specs/examples/simple_mcp.yaml --prompt "Use filesystem tools"
```

### Multiple LLM Providers
Use different AI models in the same workflow:

```yaml
llms:
  fast_model:
    type: openai
    model_name: gpt-4.1-mini
    temperature: 0.3
    
  smart_model:
    type: anthropic
    model_name: claude-sonnet-4
    temperature: 0.7
    
  local_model:
    type: ollama
    model_name: llama3
    temperature: 0.5

workflow:
  nodes:
    - id: draft
      kind: agent
      ref: fast_model  # Quick draft
    - id: refine  
      kind: agent
      ref: smart_model  # Detailed refinement
```

---

## üîó File Reference System

ELF's `@filename.ext` syntax automatically includes file contents in prompts:

### Basic Usage
```bash
# Single file
uv run elf agent specs/basic_chat.yaml --prompt "Explain @main.py"

# Multiple files  
uv run elf agent specs/basic_chat.yaml --prompt "Compare @file1.py and @file2.py"

# Mixed with regular text
uv run elf agent specs/basic_chat.yaml --prompt "Review @code.py and suggest improvements based on @guidelines.md"
```

### Supported File Types
- **Code**: `.py`, `.js`, `.ts`, `.java`, `.cpp`, etc.
- **Text**: `.txt`, `.md`, `.rst`, `.log`  
- **Config**: `.yaml`, `.yml`, `.json`, `.toml`, `.ini`
- **Data**: `.csv`, `.xml` (text-based files)

### Best Practices
- **Keep files reasonably sized** (< 10KB for best results)
- **Use descriptive filenames** (`user_auth.py` vs `utils.py`)
- **Combine with context** (`--context` flag for additional files)
- **Reference documentation** (`@README.md`, `@CHANGELOG.md`)

### Examples
```bash
# Code review with context
uv run elf agent specs/basic_chat.yaml \
  --prompt "Review @api.py for security issues" \
  --context requirements.txt --context .env.example

# Documentation generation
uv run elf agent specs/basic_chat.yaml \
  --prompt "Create API docs for @server.py based on @api_spec.yaml"

# Test generation  
uv run elf agent specs/basic_chat.yaml \
  --prompt "Write unit tests for @calculator.py following patterns in @test_example.py"
```

---

## üõ† Troubleshooting

### Common Issues

#### 1. "Command not found: elf"
```bash
# Make sure you're in the virtual environment
source .venv/bin/activate  # macOS/Linux
.venv\Scripts\activate     # Windows

# Verify installation
uv pip list | grep elf
```

#### 2. "API key not found" 
```bash
# Check your environment variables
echo $OPENAI_API_KEY
echo $ANTHROPIC_API_KEY

# Set them properly
export OPENAI_API_KEY="your-key-here"

# Or use a .env file in the project root
echo "OPENAI_API_KEY=your-key-here" > .env
```

#### 3. "Module not found" errors
```bash
# Reinstall in development mode
uv pip install -e .

# Or install dependencies
uv pip install -r requirements.txt
```

#### 4. "Workflow file not found"
```bash
# Check the file exists
ls specs/basic_chat.yaml

# Use full path if needed
uv run elf agent /full/path/to/specs/basic_chat.yaml --prompt "test"
```

#### 5. Ollama connection issues
```bash
# Make sure Ollama is running
ollama list

# Start Ollama service
ollama serve

# Test with a simple model
ollama run llama2 "Hello"
```

#### 6. uv package manager issues
```bash
# uv command not found
# Make sure uv is in your PATH - restart your terminal after installation
echo $PATH | grep -i uv

# Reinstall uv if needed
curl -LsSf https://astral.sh/uv/install.sh | sh

# Alternative: Use pip fallback
pip install -e .  # Instead of uv pip install -e .

# Clear uv cache if having dependency issues
uv cache clean

# Check uv configuration
uv --help
```

### Platform-Specific Issues

#### Windows
- Use `py` instead of `python` if you have multiple Python versions
- Use PowerShell or Command Prompt, not Git Bash for installation
- Path separators: use forward slashes `/` in file paths

#### macOS
- Install Xcode Command Line Tools: `xcode-select --install`
- Use Homebrew for Python if needed: `brew install python@3.13`

#### Linux  
- Install Python dev headers: `sudo apt-get install python3-dev`
- Some distributions need: `sudo apt-get install build-essential`

### Getting Help

1. **Check the examples**: Look in `specs/examples/` for working workflows
2. **Use verbose mode**: `uv run elf --verbose` to see detailed logs
3. **Check the issues**: [GitHub Issues](https://github.com/emson/elf/issues) 
4. **Start a discussion**: [GitHub Discussions](https://github.com/emson/elf/discussions)

---

## üìÇ Project Structure

Understanding where files go helps you organize your workflows:

```
elf/
‚îú‚îÄ‚îÄ specs/                    # Workflow definitions
‚îÇ   ‚îú‚îÄ‚îÄ basic_chat.yaml      # Simple chat workflow
‚îÇ   ‚îú‚îÄ‚îÄ agent-*.yaml         # Pre-built agent workflows  
‚îÇ   ‚îî‚îÄ‚îÄ examples/            # Example workflows
‚îÇ       ‚îú‚îÄ‚îÄ ollama_chat.yaml
‚îÇ       ‚îú‚îÄ‚îÄ mcp_workflow.yaml
‚îÇ       ‚îî‚îÄ‚îÄ python_*.yaml
‚îú‚îÄ‚îÄ src/elf/                 # ELF source code
‚îú‚îÄ‚îÄ mcp/                     # MCP server configurations
‚îî‚îÄ‚îÄ your_workflows/          # Put your custom workflows here
```

### Creating Your Own Workflows

1. **Start with an example**: Copy `specs/basic_chat.yaml`
2. **Modify gradually**: Change prompts, models, add steps
3. **Test frequently**: Run after each change
4. **Use version control**: Git track your workflow evolution

```bash
# Copy and customize
cp specs/basic_chat.yaml my_workflow.yaml

# Edit with your favorite editor
code my_workflow.yaml  # VS Code
vim my_workflow.yaml   # Vim
nano my_workflow.yaml  # Nano

# Test your changes
uv run elf agent my_workflow.yaml --prompt "test"
```

---

## üéØ Examples Gallery

### Simple Examples (Start Here)

#### Basic Chat
```bash
uv run elf agent specs/basic_chat.yaml --prompt "Explain photosynthesis"
```

#### Code Analysis  
```bash
uv run elf agent specs/basic_chat.yaml --prompt "Review this code @example.py"
```

#### Local LLM (Free)
```bash
uv run elf agent specs/examples/ollama_chat.yaml --prompt "What is machine learning?"
```

### Intermediate Examples

#### Multi-step Workflow
```bash
uv run elf agent specs/examples/prompt_chaining.yaml --prompt "Research and summarize: renewable energy"
```

#### Interactive Session
```bash
uv run elf prompt specs/basic_chat.yaml
üí¨ Prompt: Help me debug @buggy_code.py
üí¨ Prompt: Now write tests for the fixed version
üí¨ Prompt: exit
```

#### Python Function Integration  
```bash
uv run elf agent specs/examples/python_text_processor.yaml --prompt "artificial intelligence"
```

### Advanced Examples

#### Self-Improvement
```bash
uv run elf improve yaml specs/basic_chat.yaml --prompt "Make this workflow better for code review"
```

#### MCP Integration
```bash
uv run elf agent specs/examples/mcp_workflow.yaml --prompt "Calculate compound interest for $1000 at 5% for 10 years"
```

#### Claude Code Integration
```bash
# AI-powered code generation and improvement
uv run elf agent specs/examples/claude_code_example.yaml --prompt "Create a REST API with authentication"

# Self-evolving AI platform capabilities  
uv run elf agent specs/examples/claude_code_self_improvement.yaml --prompt "Add logging capabilities to ELF workflows"
```

#### Complex Workflows
```bash
uv run elf agent specs/examples/orchestration_workers.yaml --prompt "Analyze this codebase @src/"
```

---

## ü§ù Contributing

We welcome contributions! Here's how to get involved:

### Quick Contributions
- **Report bugs**: [Create an issue](https://github.com/emson/elf/issues/new)
- **Suggest features**: [Start a discussion](https://github.com/emson/elf/discussions)
- **Improve docs**: Edit README or add examples
- **Share workflows**: Submit your useful workflows

### Development Setup
```bash
git clone https://github.com/emson/elf.git
cd elf
uv venv                    # Create virtual environment (much faster than python -m venv)
source .venv/bin/activate  # Activate environment
uv pip install -e .       # Install ELF in development mode (faster than pip)

# Install development dependencies
uv pip install pytest ruff mypy

# Run tests
pytest

# Run linting
ruff check src/
mypy src/
```

**Note:** All `uv pip` commands can be replaced with regular `pip` commands if you prefer, but `uv` will be significantly faster for dependency resolution and installation.

### Areas We Need Help
- **New workflow examples** for different use cases
- **Documentation improvements** for clarity
- **MCP server integrations** for popular tools
- **Performance optimizations** for large workflows
- **Platform testing** (Windows, Linux, different Python versions)

### Code Style
- Follow PEP 8 conventions
- Use type hints for all functions
- Add tests for new features
- Update documentation

---

## üìÑ License

ELF is licensed under the [Apache License 2.0](LICENSE). This means you can freely use, modify, and distribute this software, even for commercial purposes, as long as you include the original license and copyright notice.

## üôè Acknowledgments

- Built with [LangGraph](https://github.com/langchain-ai/langgraph) for workflow orchestration
- Powered by [Rich](https://github.com/Textualize/rich) for beautiful terminal output  
- Uses [uv](https://github.com/astral-sh/uv) by [Astral](https://astral.sh/) for blazingly fast Python package management
- Supports [MCP](https://modelcontextprotocol.io/) for tool integration
- Inspired by NVIDIA's AgentIQ framework for AI workflow design patterns

---

**Ready to build your first AI workflow?** Start with the [Quick Start](#-quick-start-5-minutes) section above! üöÄ
